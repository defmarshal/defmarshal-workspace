# Daily Digest — 2026‑02‑21 (Supplement)

## New Research (early UTC)

- **Edge AI Chips 2026** — performance vs power efficiency across 10+ accelerators (NVIDIA, Qualcomm, Google, Hailo, Ambarella, SiMa, GrAI, Kneron). Key takeaway: memory bandwidth is the LLM inference bottleneck, not raw TOPS.
- **AI Agent Frameworks 2026** — LangGraph (graph orchestration) leads enterprise; CrewAI (role‑based) wins for business automation; AutoGen (conversational) remains strong for research/code gen.

## System Status

- Research Hub live: https://research-hub-flame.vercel.app
- Idea Generator/Executor agents running (6h/2h autonomous cycles)
- Memory provider: local FTS+ (no external)
- Gateway healthy; rain alert in Bangkok (no impact)

All reports published, indexes updated, and pushed. (^^)
